<!DOCTYPE HTML>
<!--
    "Thanks to HTML5 UP for this template".
    Massively by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    <head>
        <!-- Code Render-->
        <link rel="stylesheet" href="data/syntaxhighlighter/shCore.css">
        <link rel="stylesheet" href="data/syntaxhighlighter/shThemeDefault.css">
        <script type="text/javascript" src="data/syntaxhighlighter/shCore.js"></script>
        <script type="text/javascript" src="data/syntaxhighlighter/shBrushPython.js"></script>

        <!--MathJax-->
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
                    config: ["MMLorHTML.js"],
    extensions: ["mml2jax.js"],
    jax: ["input/MathML"]

        });

        </script>
        <script type="text/javascript" async
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
        <style>
            .math-container {
            overflow-x: auto;
            display: block;
        }
        </style>
        <style>
        .new_image {
            width:100%;
        }
        img {
            max-width:100%;
        }
        </style>

<style>
.slack-discuss {
    font-family: Arial, Helvetica, sans-serif;
    font-weight: 600;
    font-size: 16px;
    text-align: center;

    background-color: white;
    box-shadow: .1rem .1rem 1.2rem .1rem #467AAC;
    width: 100%;
    cursor: pointer;
    border-radius: 20px;

}

.slack-discuss:hover {
    box-shadow: .2rem .2rem 2.4rem .2rem #467AAC;
}
</style>
<style> 
#rcorners1 {
    border-radius: 25px;
    background: #ECF1F6;
    padding: 20px; 
    width: max-content;
}
</style>
<style>
    .bb {
        padding-left: 10px;
        padding-right: 10px; 
        padding-top: 7px; 
        padding-bottom: 5px; 
        background-color: #f6f8fa;
        border:1px rgb(194, 199, 204) solid;
        border-radius: 6px;
    }
</style>

        		<style>
			.logo-nav{
				background-color: #cfedff; 
				border-radius: 5px; 
				position: relative; 
				top: 3px;
			}
			.logo-nav:hover{
				background-color: #6cc7ff; 
			}
			.slack-nav{
				color: blue;
				border-bottom-color: transparent;
				background-color: #cfedff; 
				border-radius: 	5px;	
				padding-right: 	3px;
				padding-left:  	3px;
				padding-top: 	2px;
				padding-bottom: 1px;
				top: 			0px;
				
			}
		</style>
		<title>Projection</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <link rel="stylesheet" href="data/assets/css/main.css" />
        <noscript><link rel="stylesheet" href="data/assets/css/noscript.css" /></noscript>
    <link rel="icon" href="data/img/icon.png" type="image/png" sizes="16x16">
</head>    <body class="is-preload">

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Header -->
                    <header id="header">
                        <a href="index.html" class="logo">Linear Algebra</a>
                    </header>

                <!-- Nav -->
                    <nav id="nav">
                        <ul class="links">
                            <li class="active"><a href="projection.html">Projection</a></li>
                            <li><a href="least-squares.html">Least Squares(Application of projection)</a></li>
                        </ul>
                        <ul class="icons">
                            <li><a href="https://quantml.org/" style="border-bottom-color: transparent;"><img style="margin-right: 5px; margin-left: 5px;" class="logo-nav" src="data/img/icon.png" alt="logo" width="20" height="20"></a></li>
							<li><a href="https://join.slack.com/t/quantml-org/shared_invite/zt-hcmbg7fr-jPbVAUT_tjGPaKWU50qMYQ" class="fab fa-slack slack-nav" style="color: blue;"><span class="label"></span></a></li>
                            <li><a href="https://www.linkedin.com/in/yuvraj97/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
                            <li><a href="https://github.com/yuvraj97/" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
                        </ul>					</nav>
                <!-- Main -->
                    <div id="main">
                        <section class="post">
<div class='buttons'>
    <button onclick="window.location.href = 'orthogonal-subspaces.html';">&#x25C0;&nbsp;&nbsp;Orthogonal Subspaces</button>
    <button style="float: right;" onclick="window.location.href = 'least-squares.html';">Least Squares&nbsp;&nbsp;&#x25B6;</button>
</div><br>

<p>
<h1>Projection</h1>

<h2 id="vec-proj">Vector Projection</h2>
<div class="new_image">
<img src="data/img/proj-0.png" width="184" height="136" alt="" style="float:right">
Say that we have two vector <span class="bb">\(\vec{v}\in\mathbb{R}^2\)</span> and <span class="bb">\(\vec{u}\in\mathbb{R}^2\)</span>.<br>
Now <b>in space of \(\vec{v}\)</b> which vector is <b>closest</b> to \(\vec{w}\)?<br>
But let's first ask what is the space of \(\vec{v}\)?<br>
</div>
<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
    We are asking for the space of <b>a single vector</b>, a single vector can only give us a
    space in \(\mathbb{R}\) which is a <b>line</b>.<br>
    So the <b>span</b> of \(\vec{v}\) is \(C\vec{v};\quad C\in\mathbb{R}\) 
</blockquote><br>
Now we have to find a vector <b>closest</b> to \(\vec{w}\) in the <b>vector space</b> of \(\vec{v}\).<br>
Let's call this <b>closest</b> vector as \(\vec{p}\), 
this \(\vec{p}\) is the projection of \(\vec{w}\) on \(\vec{v}\).<br>
We know that \(\vec{p}\) lives in the <b>vector space</b> of \(\vec{v}\).<br>
So <span class="bb">\(\vec{p}=x\vec{v};\quad x\in\mathbb{R}\)</span>.<br>
\(\vec{p}\) is the <b>closest</b> vector to \(\vec{w}\) then the vector joining 
\(\vec{p}\) to \(\vec{w}\) is perpendicular to \(\vec{v}\).<br>
Say the vector joining \(\vec{p}\) to \(\vec{w}\) be \(\vec{e}\), and \(\vec{e} = \vec{w}-\vec{p}\)
So,<br>
<blockquote style="background-color:#f6f8fa; border-color: #fff; border-radius: 15px;">
\(\vec{v}\cdot \vec{e} =0\)<br>
\(\Rightarrow \vec{v}^T \vec{e} =0\)<br>
\(\Rightarrow \vec{v}^T (\vec{w} -\vec{p})=0\)<br>
\(\Rightarrow \vec{v}^T (\vec{w} -x\vec{v})=0\)<br>
\(\Rightarrow \vec{v}^T \vec{w} -x\vec{v}^T\vec{v}=0\)<br>
</blockquote>
\[\Rightarrow x=\frac{\vec{v}^T \vec{w}}{\vec{v}^T\vec{v}} \in\mathbb{R}\]
<b>Projection</b> of \(\vec{w}\) on \(\vec{v}\) is <span class="bb">\(\vec{p}=\vec{v}x\)</span><br>
<br>
<h3 id="vector-projection-matrix">Projection Matrix of a vector</h3>
Say we have a vector <span class="bb">\(\vec{v}\in\mathbb{R}^n\)</span> now we want a <b>matrix</b> that gives us projection 
of <b>any</b> vector onto this vector \(\vec{v}\), we call this matrix a <b>projection matrix</b>.<br>
Say this projected vector on \(\vec{v}\) be \(\vec{p}\).<br>
As we discussed above,<br>
\(\vec{p}=\vec{v}x\)<br>
\(\displaystyle \Rightarrow \vec{p}= \vec{v} \frac{\vec{v}^T \vec{w}}{\vec{v}^T\vec{v}}\)<br>
\(\displaystyle \Rightarrow \vec{p}= \frac{\vec{v} \vec{v}^T}{\vec{v}^T\vec{v}} \vec{w}\)<br>
<br>
Projection matrix\((P)\) of a vector \(\vec{v}\) is

\[\bbox[5px,border:2px solid blue]{ \color{blue}{
    \begin{matrix}
        \\    %blank line
    \quad 
    
    % equation
    \displaystyle P=\frac{\vec{v}\ \vec{v}^T}{\vec{v}^T\vec{v}} 
    %equation
    
    \quad\\
        \\    %blank line
    \end{matrix}
    }}
\]

<li>Columns of \(P\) is the <b>linear combinations</b> of \(\vec{v}\), so </li>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
Column space of \(P\) is the vector space of \(\vec{v}\).<br>
</blockquote><br>

<li>We have our <b>Projection matrix</b>\((P)\) we can take <b>projection</b> of any vector 
\(\vec{w}\) on \(\vec{v}\) by evaluating \(P\vec{w}\)</li>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
In \(P\vec{w}\) we are taking the <b>linear combination</b> of \(\vec{v}\) so the resultant 
projection of \(\vec{w}\) on \(\vec{v}\) lives in the <b>vector space</b> of \(\vec{v}\).<br>
</blockquote><br>

<li>What about the <b>rank</b> of \(P\)?</li>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
Rank of \(P\) is \(1\).<br>
Because all the columns of \(P\) is the <b>linear combination</b> of a <b>single vector</b> \(\vec{v}\).
</blockquote><br>

<li>Is \(P\) <b>symmetric</b>?</li>
\(\displaystyle P= \frac{\vec{v} \vec{v}^T}{\vec{v}^T\vec{v}} \)<br>
\(\displaystyle \Rightarrow P^T = \frac{(\vec{v} \vec{v}^T)^T}{\vec{v}^T\vec{v}} \)<br>
\(\displaystyle \Rightarrow P^T = \frac{\vec{v}^{T^T}  \vec{v}^T}{\vec{v}^T\vec{v}} \)<br>
\(\displaystyle \Rightarrow P^T = \frac{\vec{v} \vec{v}^T}{\vec{v}^T\vec{v}} \)<br>
So \(P\) is symmetric.
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
\[P=P^T\]
</blockquote><br>

<li>What if we apply the projection of a vector \(\vec{w}\) on \(\vec{v}\) <b>twice</b>?</li>
When we apply the <b>projection</b> first time, we land in the <b>vector space</b> of \(\vec{v}\).<br>
Let's say the projected vector be \(\vec{p}_1\).<br>
If we again apply the <b>projection</b> on \(\vec{p}_1\) then it project the \(\vec{p_1}\) 
into the vector space of \(\vec{v}\).<br>
But \(\vec{p}_1\) is already in <b>vector space</b> of \(\vec{v}\), so the second projection did nothing.<br>
So we can say that 
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
\[P^2=P\]
</blockquote><br>
<br>
<h2 id="why-project">Why are we doing projection?</h2>
Ok we can find the projection of a vector on another vector, <b>but why</b> are we projecting the
vector in the first place?<br>
<b>What is the benefit of projecting a vector?</b><br>
<span id="example"></span>
Say a function \(f=x_1 a+ x_2 b+ x_3 c\) is governed by 3 variables (say \(a,b,c\)) and we have \(5\) <b>noisy</b>
observation of \(f\) now we want to predict \(f\) for some set of \((a,b,c)\).<br>
Because our \(5\) observations are <b>noisy</b>  so we <b>can not</b> perfectly predict the outcome.<br>
Our observation is something like,<br>
\(f_1=x_1 a_1+ x_2 b_1+ x_3 c_1\)<br>
\(f_2=x_1 a_2+ x_2 b_2+ x_3 c_2\)<br>
\(f_3=x_1 a_3+ x_2 b_3+ x_3 c_3\)<br>
\(f_4=x_1 a_4+ x_2 b_4+ x_3 c_4\)<br>
\(f_5=x_1 a_5+ x_2 b_5+ x_3 c_5\)<br>
We can write it as,<br>
\(\begin{bmatrix}
a_1 & b_1 & c_1\\
a_2 & b_2 & c_2\\
a_3 & b_3 & c_3\\
a_4 & b_4 & c_4\\
a_5 & b_5 & c_5\\
\end{bmatrix}
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
\end{bmatrix}
=
\begin{bmatrix}
f_1\\
f_2\\
f_3\\
f_4\\
f_5\\
\end{bmatrix}
\)<br>

Here \(x_1 , x_2 , x_3\) are our parameters(unknown), so our parameter
space is \(\mathbb{R}^5\).<br>
We want to find a \(4\) dimensional plane that best fit our <b>noisy</b> data.<br>
Say
\(\begin{bmatrix} a_1 \\ a_2 \\ a_3 \\ a_4 \\ a_5 \\ \end{bmatrix} = \vec{a},\quad\)
\(\begin{bmatrix} b_1 \\ b_2 \\ b_3 \\ b_4 \\ b_5 \\ \end{bmatrix} = \vec{b},\quad\)
\(\begin{bmatrix} c_1 \\ c_2 \\ c_3 \\ c_4 \\ c_5 \\ \end{bmatrix} = \vec{c},\quad\)

 \(\begin{bmatrix}
a_1 & b_1 & c_1\\
a_2 & b_2 & c_2\\
a_3 & b_3 & c_3\\
a_4 & b_4 & c_4\\
a_5 & b_5 & c_5\\
\end{bmatrix}= \mathbb{A}, \quad\)
\(\begin{bmatrix}
x_1\\
x_2\\
x_3\\
\end{bmatrix}=\mathbb{X},\quad\)
and 
\(\begin{bmatrix}
f_1\\
f_2\\
f_3\\
f_4\\
f_5\\
\end{bmatrix}
=\mathbb{Y}\)<br>
So <span class="bb">\(\mathbb{A}\mathbb{X}=\mathbb{Y}\)</span><br>
Our data is <b>noisy</b>.<br>
<span class="bb">\(\text{Rank}(\mathbb{A})\leq 3\)</span>,
<span class="bb"> \(\mathbb{X}\in\mathbb{R}^3\)</span>,
<span class="bb"> \(\mathbb{Y}\in\mathbb{R}^5\)</span>.<br>
So there are <b>high chance</b> that \(\mathbb{Y}\) does <b>not</b> lives in <b>column space</b> of \(\mathbb{A}\).<br> 
So <b>instead</b> we find the solution for <span class="bb">\(\mathbb{A}\widehat{\mathbb{X}}=\widehat{\mathbb{Y}}\)</span>.<br>
Where \(\widehat{\mathbb{Y}}\) lives in the column space of \(\mathbb{A}\) <b>and</b> \(\widehat{\mathbb{Y}}\)
is <b>closest</b> to \(\mathbb{Y}\)
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
We can get this \(\widehat{\mathbb{Y}}\) by taking the <b>projection</b> of \(\mathbb{Y}\)
onto the <b>column space</b> of \(\mathbb{A}\)
</blockquote><br>
<br>

<h2 id="matrix-projection">Matrix Projection</h2>
Say that we have a \(m\times n\) matrix <span class="bb">\(\mathbb{A}\in\mathbb{R}^{m\times n}\)</span> and a vector 
<span class="bb">\(\vec{v}\in\mathbb{R}^n\)</span>.<br>
Then <b>projection</b> of a vector \(\vec{v}\) on a matrix \(\mathbb{A}\) <i>generally</i> means <b>projection</b>
of \(\vec{v}\) on the <b>column space</b> of matrix \(\mathbb{A}\).<br>
We can also take the <b>projection</b> of a vector \(\vec{v}\) on the <b>null space</b> of matrix \(\mathbb{A}^T\).<br>
And as we know that <b>null space</b> of \(\mathbb{A}^T\) is <b>perpendicular</b> to the <b>column space</b> of \(\mathbb{A}\).<br>
Then,

<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
Projection of a vector \(\vec{v}\) on the,<br>
<li><b>null space</b> of matrix \(\mathbb{A}^T\), and</li>
<li><b>column space</b> of matrix \(\mathbb{A}\)</li>
collectively gives us back our vector \(\vec{v}\)
</blockquote><br>
<br>

<h3 id="matrix-projection-column">Projection onto the column space of a matrix</h3>
Recall our <a style="color: royalblue" href="projection.html#example">previous example</a>, 
here we have a system of equation <span class="bb">\(\mathbb{A}\mathbb{X}=\mathbb{Y}\)</span> where there is <b>no solution</b>.<br>
Here problem was that there are <b>high chance</b> that \(\mathbb{Y}\) does <b>not</b> lives in <b>column space</b> of \(\mathbb{A}\), 
So it does <b>not</b> have a solution.<br> 
So we go for the <b>closest</b> solution.<br>
<span class="bb">\(\mathbb{A}\widehat{\mathbb{X}}=\widehat{\mathbb{Y}}\)</span><br>
where, \(\widehat{\mathbb{Y}}\) lives in the <b>column space</b> of \(\mathbb{A}\), so.<br>
<!--(And we put a <b>hat</b> on\(\mathbb{X}\) just to show that it's the estimated \(\mathbb{X}\)).<br>-->
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\(\widehat{\mathbb{Y}}\) is the <b>linear combinations</b> of the columns of \(\mathbb{A}\).
</blockquote>
(vector)\(\widehat{\mathbb{Y}}\) lives in the column space \(\mathbb{A}\) <b>and</b> 
(vector)\(\mathbb{Y}\) is at some angle to the column space of \(\mathbb{A}\), So <br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
The vector \(\mathbb{Y} - \widehat{\mathbb{Y}}\) is perpendicular to the <b>column space</b> of \(\mathbb{A}\)
</blockquote>
\(\Rightarrow \mathbb{Y} - \widehat{\mathbb{Y}}\) is also perpendicular to the column <b>vectors</b> of \(\mathbb{A}\)<br>
\(\Rightarrow\) <span class="bb">\(\vec{a}^T (\mathbb{Y} - \widehat{\mathbb{Y}})=0\)</span>, 
<span class="bb">\(\vec{b}^T (\mathbb{Y} - \widehat{\mathbb{Y}})=0\)</span> and
<span class="bb">\(\vec{c}^T (\mathbb{Y} - \widehat{\mathbb{Y}})=0\)</span>
where \(\vec{a},\) \(\vec{b}\) and \(\vec{c}\) are the column vector of \(\mathbb{A}\).<br>
We can write it as,<br>

\[\bbox[5px,border:2px solid blue]{ \color{blue}{
    \begin{matrix}
        \\    %blank line
    \quad 
    
    % equation
    \displaystyle \mathbb{A}^T(\mathbb{Y} - \widehat{\mathbb{Y}})=0
    %equation
    
    \quad\\
        \\    %blank line
    \end{matrix}
    }}
\]

Notice that \(\mathbb{Y} - \widehat{\mathbb{Y}}\) lives in \((N(A^T))\)
<li>The <a style="color: royalblue" href="fundamental-subspaces.html#left-null-space">Left Null Space</a>
of matrix \(\mathbb{A}\) OR say </li>
<li>The <a style="color: royalblue" href="null-space.html">Null Space</a> of \(\mathbb{A}^T\).<br></li> 
And <b>Null Space</b> of \(\mathbb{A}^T\) is <b>perpendicular</b> to the <b>column space</b> of \(\mathbb{A}\).<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
So \(\mathbb{Y} - \widehat{\mathbb{Y}}\) is  <b>perpendicular</b> to the <b>column space</b> of \(\mathbb{A}\).<br>
</blockquote>
\(\mathbb{A}^T(\mathbb{Y} - \widehat{\mathbb{Y}})=0\) <b>and</b> \(\widehat{\mathbb{Y}}=\mathbb{A}\widehat{\mathbb{X}}\)<br>
\(\Rightarrow \mathbb{A}^T(\mathbb{Y} - \mathbb{A}\widehat{\mathbb{X}})=0\)<br>
\(\Rightarrow \mathbb{A}^T \mathbb{Y} - \mathbb{A}^T\mathbb{A}\widehat{\mathbb{X}}=0\)<br>
\(\Rightarrow \mathbb{A}^T\mathbb{A}\widehat{\mathbb{X}}=\mathbb{A}^T \mathbb{Y}\)<br>

\[\bbox[5px,border:2px solid blue]{ \color{blue}{
    \begin{matrix}
        \\    %blank line
    \quad 
    
    % equation
    \displaystyle \widehat{\mathbb{X}}=\left(\mathbb{A}^T\mathbb{A}\right)^{-1}\mathbb{A}^T \mathbb{Y}
    %equation
    
    \quad\\
        \\    %blank line
    \end{matrix}
    }}
\]

Our <b>projection</b> of \(\mathbb{Y}\) on the columnn space of \(\mathbb{A}\) is \(\widehat{\mathbb{Y}}\) .<br>
<span class="bb">\(\widehat{\mathbb{Y}}=\mathbb{A}\widehat{\mathbb{X}}\)</span> and <span class="bb">\(\widehat{\mathbb{X}}=(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T \mathbb{Y}\)</span>, so<br>
<br>
<li>Projection\((\widehat{\mathbb{Y}})\) of \(\mathbb{Y}\) on the <b>column space</b> of \(\mathbb{A}\):</li>

\[\bbox[5px,border:2px solid blue]{ \color{blue}{
    \begin{matrix}
        \\    %blank line
    \quad 
    
    % equation
    \displaystyle \widehat{\mathbb{Y}}=\mathbb{A}\left(\mathbb{A}^T\mathbb{A}\right)^{-1}\mathbb{A}^T \mathbb{Y}
    %equation
    
    \quad\\
        \\    %blank line
    \end{matrix}
    }}
\]

<br>
So our <b>Projection Matrix</b> is, 

\[\bbox[5px,border:2px solid blue]{ \color{blue}{
    \begin{matrix}
        \\    %blank line
    \quad 
    
    % equation
    \displaystyle P=\mathbb{A}\left(\mathbb{A}^T\mathbb{A}\right)^{-1}\mathbb{A}^T
    %equation
    
    \quad\\
        \\    %blank line
    \end{matrix}
    }}
\]

<li>Is \(P\) <b>symmetric</b>?</li>
\(\displaystyle P= \mathbb{A}(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T\)<br>
\(\displaystyle \Rightarrow P^T = \left(\mathbb{A}(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T\right)^T\)<br>
\(\displaystyle \Rightarrow P^T = \mathbb{A}^{T^T}((\mathbb{A}^T\mathbb{A})^{-1})^T\mathbb{A}^T\)<br>
\(\displaystyle \Rightarrow P^T = \mathbb{A}^{T^T}\left((\mathbb{A}^T\mathbb{A})^T\right)^{-1}\mathbb{A}^T\)<br>
\(\displaystyle \Rightarrow P^T = \mathbb{A}^{T^T}(\mathbb{A}^T\mathbb{A}^{T^T})^{-1}\mathbb{A}^T\)<br>
\(\displaystyle \Rightarrow P^T = \mathbb{A}(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T\)<br>
So \(P\) is symmetric.
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
\[P=P^T\]
</blockquote><br>

<li>What if we project <b>vector</b> \(\mathbb{Y}\) on the <b>column space</b> of a matrix \(\mathbb{A}\) of a matrix \(\mathbb{A}\) <b>twice</b>?</li>
When we apply the <b>projection</b> first time, we land in the <b>column space</b> of \(\mathbb{A}\).<br>
Let's say the projected vector be \(\widehat{\mathbb{Y}}\).<br>
If we again project the \(\widehat{\mathbb{Y}}\) on the <b>column space</b> of \(\mathbb{A}\) 
then the resultant vector will be \(\widehat{\mathbb{Y}}\).<br>
Because \(\widehat{\mathbb{Y}}\) is already in <b>column space</b> of \(\mathbb{A}\), so the second projection did nothing.<br>
So we can say that 
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
\[P^2=P\]
</blockquote><br>
<br>
Let's look at the extreme cases,<br>
Suppose we want to take projection of a vector \(\vec{b}\) in the <b>column space</b> of a matrix \(\mathbb{A}\).<br>

\(1.\) <b>What If the vector \(\vec{b}\) is <b>perpendicular</b> to the <b>column space</b> of matrix \(\mathbb{A}\)?</b>
<dl><dd>
    First let's think about the space of vector<b>s</b> who are <b>perpendicular</b> to the <b>column space</b> of matrix \(\mathbb{A}\).<br>
    Space <b>perpendicular</b> to the <b>column space</b> is <b>Null space</b> of \(\mathbb{A}^T\).<br>
    So \(\vec{b}\) lives in the <b>Null space</b> of \(\mathbb{A}^T\).<br>
    So, 
    <blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
    \(\mathbb{A}^T\vec{b}=\vec{0}\)
    </blockquote>
    <li><b>projection matrix</b>\((P)\) of the <b>column space</b> of a matrix \(\mathbb{A}\) is,</li>
    <blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">    
        \(P= \mathbb{A}(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T\)        
    </blockquote>
    And <b>projection</b>\(P\) of \(\vec{b}\) in the <b>column space</b> of a matrix \(\mathbb{A}\) is \(P\vec{b}\) <br>
    \(P\vec{b}= \mathbb{A}(\mathbb{A}^T\mathbb{A})^{-1}\underbrace{\mathbb{A}^T\vec{b}}_{=\vec{0}}=\vec{0}\)
</dd></dl>\(2.\) <b>What If the vector \(\vec{b}\) is <b>in</b> the <b>column space</b> of \(m\times n\) matrix \(\mathbb{A}\)?</b>
<dl><dd>
    <b>Vectors</b> in the <b>column space</b> of \(\mathbb{A}\) is the <b>linear combinations</b> of the column vectors of matrix\(\mathbb{A}\).<br>
    We can write the all the linear combinations of matrix all as \(\mathbb{A}\vec{x};\quad\vec{x}\in\mathbb{R}^n\).<br>
    And we are saying that  \(\vec{b}\) is <b>in</b> the <b>column space</b> of matrix \(\mathbb{A}\), so ,<br>
    <blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
    \(\vec{b}=\mathbb{A}\vec{x};\quad\vec{x}\in\mathbb{R}^n\).
    </blockquote>
    So <b>projection</b>\(P\) of \(\vec{b}\) in the <b>column space</b> of a matrix \(\mathbb{A}\) is \(P\vec{b}\) <br>
    \(P\vec{b}= \mathbb{A}(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T\vec{b}\).<br>
    \(P\vec{b}= \mathbb{A}\underbrace{(\mathbb{A}^T\mathbb{A})^{-1}\mathbb{A}^T\mathbb{A}}_{\mathcal{I}(  identity)}\vec{x}\).<br>
    \(P\vec{b}= \mathbb{A}\vec{x}\).<br>
    \(P\vec{b}= \vec{b}\).<br>
    So projecting \(\vec{b}\)(which is already in the column space of \(\mathbb{A}\)) on the the <b>column space</b> of \(\mathbb{A}\)
    changes nothing.<br>
</dd></dl>
</p>

<br>
<div onclick="location.href = 'https://join.slack.com/t/quantml-org/shared_invite/zt-hcmbg7fr-jPbVAUT_tjGPaKWU50qMYQ';" class="slack-discuss" style="color: #406b94;">Join our Slack <i class="fab fa-slack"> </i>  discussion forum</div>
<br>

<div class='buttons'>
    <button onclick="window.location.href = 'orthogonal-subspaces.html';">&#x25C0;&nbsp;&nbsp;Orthogonal Subspaces</button>
    <button style="float: right;" onclick="window.location.href = 'least-squares.html';">Least Squares&nbsp;&nbsp;&#x25B6;</button></div><br>
                        </section>
                    </div>
            </div>
            <!-- Highlight all -->
            <script type="text/javascript">
                SyntaxHighlighter.all()
            </script>

            <!-- Accordions -->

<script>
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
    acc[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var panel = this.nextElementSibling;
        if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
        } else {
            panel.style.maxHeight = panel.scrollHeight + "px";
        }
    });
}
</script>
        <!-- Scripts -->
            <script src="data/assets/js/jquery.min.js"></script>
            <script src="data/assets/js/jquery.scrollex.min.js"></script>
            <script src="data/assets/js/jquery.scrolly.min.js"></script>
            <script src="data/assets/js/browser.min.js"></script>
            <script src="data/assets/js/breakpoints.min.js"></script>
            <script src="data/assets/js/util.js"></script>
            <script src="data/assets/js/main.js"></script>

    </body>
</html>