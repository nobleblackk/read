<!DOCTYPE HTML>
<!--
    "Thanks to HTML5 UP for this template".
    Massively by HTML5 UP
    html5up.net | @ajlkn
    Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    <head>
        <!-- Code Render-->
        <link rel="stylesheet" href="../syntaxhighlighter/shCore.css">
        <link rel="stylesheet" href="../syntaxhighlighter/shThemeDefault.css">
        <script type="text/javascript" src="../syntaxhighlighter/shCore.js"></script>
        <script type="text/javascript" src="../syntaxhighlighter/shBrushPython.js"></script>

        <!--MathJax-->
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
                    config: ["MMLorHTML.js"],
    extensions: ["mml2jax.js"],
    jax: ["input/MathML"]

        });

        </script>
        <script type="text/javascript" async
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
        <style>
            .math-container {
            overflow-x: auto;
            display: block;
        }
        </style>
        <style>
        .new_image {
            width:100%;
        }
        img {
            max-width:100%;
        }
        </style>

<style>
.accordion {
    border: 0px solid black;
    border-color: black;
    background-color: #FFC2C2;
    color: black;
    width: 100%;
    text-align: center;
    font-size: 16px;
    cursor: pointer;
    transition: 0.4s;

}

.active, .accordion:hover {
    background-color:#C2E7FF;
}

.accordion:after {
    content: '\002B';
    color: #777;
    font-weight: bold;
    float: right;
    margin-left: 5px;
}

.active:after {
    content: "\2212";
}

.panel {
    padding: 0 18px;
    background-color: white;
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.2s ease-out;
}
</style>
        <title>Diagonalization of a Matrix</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <link rel="stylesheet" href="../assets/css/main.css" />
        <noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
    </head>
    <body class="is-preload">

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Header -->
                    <header id="header">
                        <a href="../../index.html" class="logo">Linear Algebra</a>
                    </header>

                <!-- Nav -->
                    <nav id="nav">
                        <ul class="links">
                            <li class="active"><a href="diagonalization.html">Diagonalization of a Matrix</a></li>
                        </ul>
                        <ul class="icons">
                            <li><a href="https://www.linkedin.com/in/yuvraj97/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
                            <li><a href="https://github.com/yuvraj97/" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
                        </ul>					</nav>
                <!-- Main -->
                    <div id="main">
                        <section class="post">
<div class='buttons'>
    <button onclick="window.location.href = 'orthogonal-matrices.html';">&#x25C0;&nbsp;&nbsp;Orthonormal Vectors</button>
    <button style="float: right;" onclick="window.location.href = '.html';">--&nbsp;&nbsp;&#x25B6;</button>
</div><br>

<p>
<h2>Diagonalization of a Matrix</h2>
Say that we have a \(n\times n\) <b>non-singular</b> matrix \(A\) with 
\(n\) <b>independent</b> <b>eigenvectors</b> (say \(\vec{x}_1,\vec{x}_2,\cdots,\vec{x}_n\)).<br>
We put these <b>eigenvectors</b> (\(\vec{x}_1,\vec{x}_2,\cdots,\vec{x}_n\)) in a matrix (say \(S\)).<br>
\[
S=\begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots &  \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}
\]
\[A\vec{x}_i=\lambda_i\vec{x}_i;\quad 
\left\{\begin{matrix}
    \vec{x}_i\text{ is eigenvector}\\
    \lambda_i\text{ is eigenvalue}
    \end{matrix}\right.
\]
Let's calculate \(AS\)<br>
\(AS = A \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots &  \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}\)<br>

\(\Rightarrow AS = \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 A\vec{x}_{1} & A\vec{x}_{2} & \cdots &  A\vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}\)<br>

\(\Rightarrow AS = \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \lambda_1\vec{x}_{1} & \lambda_2\vec{x}_{2} & \cdots &  \lambda_n\vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}\)<br>

\(\Rightarrow AS = \begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots & \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix}
 \underbrace{\begin{bmatrix}
 \lambda_1 &     0     & \cdots  &    0    \\  
 0         & \lambda_2 & \cdots  &    0    \\  
 \vdots    & \vdots    & \ddots  & \vdots    \\  
 0         &    0      & \cdots  &    \lambda_n    \\  
\end{bmatrix}}_{\text{say }\Lambda}
 \)<br>

\(AS=S\Lambda\)<br>
because \(S\) has independent columns so \(S^{-1}\) exists, so<br>

<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\[\Lambda =S^{-1}AS\]
This is Diagonalization.
</blockquote><br>

We can get a factorization of \(A\)<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\[A=S\Lambda S^{-1}\]
</blockquote><br>
<br>

<h2>Power of a matrix</h2>
Now let's see how \(A=S\Lambda S^{-1}\) helps us in calculating \(A^k\) for \(k=\{1,2,3,\cdots\}\)<br>
We know that,<br>
\[A\vec{x}_i=\lambda_i\vec{x}_i;\quad 
\left\{\begin{matrix}
    \vec{x}_i\text{ is eigenvector}\\
    \lambda_i\text{ is eigenvalue}
    \end{matrix}\right.
\]
Now let's calculate <b>eigenvectors</b> and <b>eigenvalues</b> of \(A^2\).<br>
\(AA\vec{x}_i=\lambda_i (A \vec{x}_i)\)<br>
\(\Rightarrow A^2\vec{x}_i=\lambda_i^2\vec{x}_i\)<br>
So <b>eigenvectors</b> of \(A^2\) remains same.<br>
But <b>eigenvalues</b> of \(A^2\) becomes \(\lambda^2\).<br>
<br>
We can also get it by \(A=S\Lambda S^{-1}\).<br>
\(A=S\Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda (S^{-1}S)\Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda \mathcal{I}\Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda \Lambda S^{-1}\)<br>
\(\Rightarrow A^2=S\Lambda^2 S^{-1}\)<br>
where,
\(\Lambda^2=\begin{bmatrix}
 \lambda_1^2 &     0     & \cdots  &    0    \\  
 0         & \lambda_2^2 & \cdots  &    0    \\  
 \vdots    & \vdots    & \ddots  & \vdots    \\  
 0         &    0      & \cdots  &    \lambda_n^2    \\  
\end{bmatrix}\)<br>
<br>
Now we can get formula for \(k^{\text{th}}\) power of \(A\).<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\[A^k = S\Lambda^k S^{-1}\]
So <b>eigenvectors</b> of \(A^k\) remains same as the <b>eigenvectors</b> of \(A\).<br>
But <b>eigenvalues</b> of \(A^k\) becomes \(\lambda^k\).<br>
</blockquote>
So now we can find power of matrices quickly, if we have the <b>eigenvectors(independent)</b> of that matrix.<br>
<br>

When we call a matrix \(A\) <b>stable</b>?<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
A matrix \(A\) is <b>stable</b> if \(A^k\to 0\) as \(k\to\infty\).<br>
And \(A^k\to 0\) as \(k\to\infty\) <b>if</b>,<br>
\(|\lambda_i| \lt 1;\quad\) \(\forall\ i\in\{1,2,\cdots n\}\)
</blockquote><br>

When a matrix \(A\) is <b>Diagonalizable?</b><br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
<b>Diagonalizable</b> matrix has \(n\) <b>independent eigenvectors</b>.<br>
So \(A\) is <b>diagonalizable</b> if, all \(\lambda\)'s are different.<br>
\(\lambda_i\neq\lambda_j;\quad \forall \ i\neq j\)<br>
<!--\(\forall\ i\in\{1,2,\cdots n\}\)-->
</blockquote><br>

<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
If all the <b>eigenvalues</b> are different then all the <b>eigenvectors</b> are <b>independent</b>.<br>
<b>But</b> reverse is not true, <b>independent</b> of <b>eigenvectors</b> does <b>not</b>
implies that all <b>eigenvalues</b> are different.<br>
<b>Example</b><br>
Say \(A=\mathcal{I}_{3\times 3}=\begin{bmatrix}
 1      & 0 &    0    \\  
 0      & 1 &    0    \\  
 0      & 0 &    1 \\  
\end{bmatrix}\)<br>
So when we apply transformation of \(\mathcal{I}\) nothing changes so every vector is an eigenvector for \(\mathcal{I}\).<br>
But there is only <b>one</b> <b>eigenvalue</b> and that is \(1\).
</blockquote><br>
<br>

<h2>\(\vec{u}_{k+1}=A\vec{u}_k\)</h2>
Say we have a vector \(\vec{u}_0\) and a matrix(<b>non-singular</b>) \(A\), with \(n\) <b>independent</b> <b>eigenvectors</b>.<br>
We iteratively apply transformation \(A\) on \(\vec{u}_0\).<br>
\[\vec{u}_{k+1}=A\vec{u}_k\]
\(\vec{u}_{1}=A\vec{u}_0\)<br>
\(\vec{u}_2=A^2\vec{u}_0\)<br>
\(\vec{u}_k=A^k\vec{u}_0\)<br>
<br>
How can we find \(\vec{u}_k\) for an arbitrary large \(k\).<br>
\(\vec{u}\) lives in the column space of \(A\), and \(A\) has \(n\) <b>independent</b> <i>eigenvectors</i>
so we can say that \(\vec{u}\) lives in the vector space spanned by these <i>eigenvectors</i>.<br>
so \(\vec{u}\) is the <b>linear combination</b> of these <i>eigenvectors</i>.<br>
say the <b>eigenvectors</b> of \(A\) are \(\vec{x}_1,\vec{x}_2,\cdots,\vec{x}_n\) 
and <b>eigenvalues</b> of \(A\) are \(\lambda_1,\lambda_2,\cdots,\lambda_n\) <br>
So we can say that,<br>
\(\vec{u}_0=c_1\vec{x}_1+c_2\vec{x}_2+\cdots+c_n\vec{x}_n\)<br>
\(\Rightarrow A\vec{u}_0=c_1A\vec{x}_1+c_2A\vec{x}_2+\cdots+c_nA\vec{x}_n\)<br>
\(\Rightarrow A\vec{u}_0=c_1\lambda\vec{x}_1+c_2\lambda\vec{x}_2+\cdots+c_n\lambda\vec{x}_n\)<br>
\(\Rightarrow A^{k}\vec{u}_0=c_1\lambda^{k}\vec{x}_1+c_2\lambda^{k}\vec{x}_2+\cdots+c_n\lambda^{k}\vec{x}_n\)<br>
\(\Rightarrow A^{k}\vec{u}_0=\Lambda^k S \vec{c}\)<br>
\(\Lambda=\begin{bmatrix}
 \lambda_1 &     0     & \cdots  &    0    \\  
 0         & \lambda_2 & \cdots  &    0    \\  
 \vdots    & \vdots    & \ddots  & \vdots    \\  
 0         &    0      & \cdots  &    \lambda_n    \\  
\end{bmatrix};\quad\)
\(S=\begin{bmatrix}
 \vdots & \vdots & \cdots & \vdots \\  
 \vec{x}_{1} & \vec{x}_{2} & \cdots &  \vec{x}_{n}   \\
 \vdots & \vdots & \cdots & \vdots \\
 \end{bmatrix};\quad\)
\(\vec{c}=\begin{bmatrix} c_1\\c_2\\ \vdots \\c_n \end{bmatrix}\)<br>
So,<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\[\vec{u}_k = A^{k}\vec{u}_0=\Lambda^k S\ \vec{c}\]
</blockquote><br>
<br>

<h4>Fibonacci example</h4>
Fibonacci sequence: \(0,1,1,2,3,5,\cdots\)<br>
How can we find \(F_k\) for an arbitrary large \(k\).<br>
\(F_{k+2}=F_{k+1}+F_k\)<br>
Now let's write it in form of \(\vec{u}_{k+1}=A\vec{u}_k\)<br>
say \(\vec{u}_k= \begin{bmatrix} F_{k+1}\\F_k\\ \end{bmatrix}\)<br>
and \(\vec{u}_{k+1}=A\vec{u}_k\)<br>
\(\Rightarrow \vec{u}_{k+1}=A\begin{bmatrix} F_{k+1}\\F_k\\ \end{bmatrix}\)<br>
\(\Rightarrow A=\begin{bmatrix} 1&1\\1&0\\ \end{bmatrix}\)<br>
What are it's <i>eigenvalues</i> and <i>eigenvectors</i>.<br>
<blockquote style="background-color:#ECF1F6;">

\(\text{det}(A - \lambda\mathcal{I})=\begin{vmatrix}
        1-\lambda & 1 \\
        1 & -\lambda \\
        \end{vmatrix}\)<br>
\(\text{det}(A - \lambda\mathcal{I})=\lambda^2-\lambda-1\)<br>
for \(\text{det}(A - \lambda\mathcal{I})=0\) we get,<br>
\(\lambda_1 = \frac{1+\sqrt{5}}{2}\)<br>
\(\lambda_2 = \frac{1-\sqrt{5}}{2}\)<br>
We get our <b>eigenvalues</b> \(\lambda_1, \lambda_2\).<br>
\((A-\lambda\mathcal{I})\vec{x}=0\)<br>
\(\begin{bmatrix}
        1-\lambda & 1 \\
        1 & -\lambda \\
        \end{bmatrix}
        \vec{x}=0
\)<br>
by solving it we get, <br>
\(\vec{x}=\begin{bmatrix} \lambda\\ 1 \end{bmatrix}\)<br>
So our <b>eigenvectors</b> are 
\(\vec{x}_1=\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix},\quad\)
\(\vec{x}_2=\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}\)<br>
</blockquote><br>
Now we get our <i>eigenvectors</i> and <i>eigenvalues</i>.<br>
\(\vec{u}\) lives in the vector space spanned by these <i>eigenvectors</i>.<br>
so \(\vec{u}\) is the <b>linear combination</b> of these <i>eigenvectors</i>.<br>
we found the <i>eigenvectors</i> of \(A\) \(\vec{x}_1,\vec{x}_2\)
and <i>eigenvalues</i> of \(A\) are \(\lambda_1,\lambda_2\)<br>
So we can say that,<br>
\(\vec{u}_0=c_1\vec{x}_1+c_2\vec{x}_2\)<br>
\(\Rightarrow A\vec{u}_0=c_1A\vec{x}_1+c_2A\vec{x}_2\)<br>
\(\Rightarrow A\vec{u}_0=c_1\lambda_1\vec{x}_1+c_2\lambda_2\vec{x}_2\)<br>
So,<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\[\vec{u}_k=A^{k}\vec{u}_0=c_1\left(\frac{1+\sqrt{5}}{2}\right)^{k}\vec{x}_1+c_2\left(\frac{1-\sqrt{5}}{2}\right)^{k}\vec{x}_2\]
</blockquote><br>
Now let's find \(c_1,c_2\).<br>
we know \(\vec{u}_0=\begin{bmatrix} F_{1}\\F_0\\ \end{bmatrix}\)<br>
\(\Rightarrow \vec{u}_0=\begin{bmatrix} 1\\0\\ \end{bmatrix}\)<br>
And we know that \(\vec{u}_0=c_1\vec{x}_1+c_2\vec{x}_2\) so,<br>
\(\vec{u}_0=c_1\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix}+c_2\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}\)<br>
\(\Rightarrow c_1\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix}+c_2\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}=\begin{bmatrix} 1\\0\\ \end{bmatrix}\)<br>
Now we got system of equations,<br>
\(c_1\lambda_1 + c_2\lambda_2 = 1\)<br>
\(c_1 + c_2 = 0\)<br>
by solving we get, \(c_1=\frac{1}{\lambda_1-\lambda_2}\) and \(c_2=\frac{-1}{\lambda_1-\lambda_2}\)<br>
\(\lambda_1-\lambda_2 = \frac{1+\sqrt{5}}{2} - \frac{1-\sqrt{5}}{2}=\sqrt{5}\)
we know that \(\vec{u}_k = A^k\vec{u}_0=c_1\lambda_1^k\vec{x}_1+c_2\lambda_2^k\vec{x}_2\)<br>
\(\Rightarrow \vec{u}_k =\frac{1}{\lambda_1-\lambda_2}\left(\lambda_1^k\vec{x}_1-\lambda_2^k\vec{x}_2\right)\)<br>
\(\Rightarrow \vec{u}_k =\frac{1}{\lambda_1-\lambda_2}\left(
            \lambda_1^k\begin{bmatrix} \lambda_1\\ 1 \end{bmatrix}-
            \lambda_2^k\begin{bmatrix} \lambda_2\\ 1 \end{bmatrix}\right)\)<br>
\(\Rightarrow \vec{u}_k =\frac{1}{\lambda_1-\lambda_2}\left(
            \begin{bmatrix} \lambda_1^{k+1}\\ \lambda_1^k \end{bmatrix}-
            \begin{bmatrix} \lambda_2^{k+1}\\ \lambda_2^k \end{bmatrix}\right)\)<br>
We know that, \(\vec{u}_k= \begin{bmatrix} F_{k+1}\\F_k\\ \end{bmatrix}\)<br>
So,<br>
\[F_k=\frac{\lambda_1^k - \lambda_2^k}{\lambda_1-\lambda_2}\]
\(\lambda_1 = \frac{1+\sqrt{5}}{2}\) and \(\lambda_2 = \frac{1-\sqrt{5}}{2}\) so<br>
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
\[F_k=\frac{1}{\sqrt{5}}\left(   \left(\frac{1+\sqrt{5}}{2}\right)^k - \left(\frac{1-\sqrt{5}}{2}\right)^k  \right)\]
</blockquote><br>

<blockquote style="background-color:#ECF1F6;">
For large \(k,\quad\) \(\left(\frac{1-\sqrt{5}}{2}\right)^{k}\approx 0\)<br>
So 
\[F_k\approx \frac{1}{\sqrt{5}}\left(   \left(\frac{1+\sqrt{5}}{2}\right)^k \right)\]
\(\frac{1+\sqrt{5}}{2}\) is known as <a style="color:blue" href="https://en.wikipedia.org/wiki/Golden_ratio">Golden Ratio</a>
</blockquote><br>














<!--
<blockquote style="background-color:#ECF1F6;  border-left-color:#467AAC">
</blockquote>
-->

<!--
Symmetric matrix will give us pure Real eigenvalue, and
Anti Symmetric matrix will give us pure Complex eigenvalue, and
-->
</p>

<button class="accordion">\(\text{Discussion}\)</button>
<div class="panel">
    <script src="https://utteranc.es/client.js"
        repo="yuvraj97/stats.github.io"
        issue-term="introduction-intro-discussion"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
</div>
<button class="accordion">\(\text{Put up a question}\)</button>
<div class="panel">
    <script src="https://utteranc.es/client.js"
        repo="yuvraj97/stats.github.io"
        issue-term="introduction-intro-questions"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
</div>
<br><br>
<div class='buttons'>
    <button onclick="window.location.href = 'orthogonal-matrices.html';">&#x25C0;&nbsp;&nbsp;Orthonormal Vectors</button>
    <button style="float: right;" onclick="window.location.href = '.html';">--&nbsp;&nbsp;&#x25B6;</button>
</div><br>
                        </section>
                    </div>
            </div>
            <!-- Highlight all -->
            <script type="text/javascript">
                SyntaxHighlighter.all()
            </script>

            <!-- Accordions -->

<script>
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
    acc[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var panel = this.nextElementSibling;
        if (panel.style.maxHeight) {
            panel.style.maxHeight = null;
        } else {
            panel.style.maxHeight = panel.scrollHeight + "px";
        }
    });
}
</script>
        <!-- Scripts -->
            <script src="../assets/js/jquery.min.js"></script>
            <script src="../assets/js/jquery.scrollex.min.js"></script>
            <script src="../assets/js/jquery.scrolly.min.js"></script>
            <script src="../assets/js/browser.min.js"></script>
            <script src="../assets/js/breakpoints.min.js"></script>
            <script src="../assets/js/util.js"></script>
            <script src="../assets/js/main.js"></script>

    </body>
</html>